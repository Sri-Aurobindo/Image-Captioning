{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from data_loader import get_loader\n",
    "from torchvision import transforms\n",
    "\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                         \n",
    "    transforms.RandomCrop(224),                      \n",
    "    transforms.RandomHorizontalFlip(),               \n",
    "    transforms.ToTensor(),                           \n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      \n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "vocab_threshold = 5\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=False)\n",
    "\n",
    "\n",
    "\n",
    "sample_caption = 'A person doing a trick on a rail while riding a skateboard.'\n",
    "import nltk\n",
    "\n",
    "sample_tokens = nltk.tokenize.word_tokenize(str(sample_caption).lower())\n",
    "print(sample_tokens)\n",
    "\n",
    "sample_caption = []\n",
    "\n",
    "start_word = data_loader.dataset.vocab.start_word\n",
    "print('Special start word:', start_word)\n",
    "sample_caption.append(data_loader.dataset.vocab(start_word))\n",
    "print(sample_caption)\n",
    "\n",
    "sample_caption.extend([data_loader.dataset.vocab(token) for token in sample_tokens])\n",
    "print(sample_caption)\n",
    "\n",
    "end_word = data_loader.dataset.vocab.end_word\n",
    "print('Special end word:', end_word)\n",
    "\n",
    "sample_caption.append(data_loader.dataset.vocab(end_word))\n",
    "print(sample_caption)\n",
    "\n",
    "sample_caption = torch.Tensor(sample_caption).long()\n",
    "print(sample_caption)\n",
    "\n",
    "\n",
    "print (dict(list(data_loader.dataset.vocab.word2idx.items())[:10]))\n",
    "\n",
    "\n",
    "print('Total number of tokens in vocabulary:', len(data_loader.dataset.vocab))\n",
    "\n",
    "\n",
    "vocab_threshold = 5\n",
    "\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=False)\n",
    "\n",
    "print('Total number of tokens in vocabulary:', len(data_loader.dataset.vocab))\n",
    "vocab_threshold = 10\n",
    "\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=False)\n",
    "\n",
    "print('Total number of tokens in vocabulary:', len(data_loader.dataset.vocab))\n",
    "\n",
    "vocab_threshold = 10\n",
    "\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=False)\n",
    "\n",
    "print('Total number of tokens in vocabulary:', len(data_loader.dataset.vocab))\n",
    "\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_from_file=True)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(data_loader.dataset.caption_lengths)\n",
    "lengths = sorted(counter.items(), key=lambda pair: pair[1], reverse=True)\n",
    "for value, count in lengths:\n",
    "    print('value: %2d --- count: %5d' % (value, count))\n",
    "\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "\n",
    "indices = data_loader.dataset.get_indices()\n",
    "print('{} sampled indices: {}'.format(len(indices), indices))\n",
    "\n",
    "new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "data_loader.batch_sampler.sampler = new_sampler\n",
    "\n",
    "for batch in data_loader:\n",
    "    images, captions = batch[0], batch[1]\n",
    "    break\n",
    "    \n",
    "print('images.shape:', images.shape)\n",
    "print('captions.shape:', captions.shape)\n",
    "\n",
    "\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "\n",
    "embed_size = 256\n",
    "\n",
    "encoder = EncoderCNN(embed_size)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    encoder = encoder.cuda()\n",
    "    \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    images = images.cuda()\n",
    "\n",
    "features = encoder(images)\n",
    "\n",
    "print('type(features):', type(features))\n",
    "print('features.shape:', features.shape)\n",
    "\n",
    "\n",
    "assert (features.shape[0]==batch_size) & (features.shape[1]==embed_size), \"The shape of the encoder output is incorrect.\"\n",
    "\n",
    "hidden_size = 512\n",
    "\n",
    "\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    decoder = decoder.cuda()\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    captions = captions.cuda()\n",
    "outputs = decoder(features, captions)\n",
    "\n",
    "print('type(outputs):', type(outputs))\n",
    "print('outputs.shape:', outputs.shape)\n",
    "\n",
    "\n",
    "assert (outputs.shape[0]==batch_size) & (outputs.shape[1]==captions.shape[1]) & (outputs.shape[2]==vocab_size), \"The shape of the decoder output is incorrect.\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
